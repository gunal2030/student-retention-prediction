{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7127ecac-7dc1-47e8-bc4d-02b76ad645c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['learner_signup_datetime', 'opportunity_id', 'opportunity_name', 'opportunity_category', 'opportunity_end_date', 'gender', 'country', 'entry_created_at', 'status_description', 'status_code', 'apply_date', 'opportunity_start_date', 'start_date_missing', 'age', 'age_band', 'apply_lag', 'start_lag', 'opportunity_duration', 'signup_cohort', 'completion_flag', 'stage_reached', 'institution_name']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"AI_Cleaned.csv\", encoding=\"latin1\")\n",
    "print(data.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a88caa2c-eb5d-4bc4-9c97-7c28b1f87339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ‘¥ Collaborative Recommendations for 'Zhuhai No.1 High School International Department':\n",
      "                              Reference Institution  \\\n",
      "0  Zhuhai No.1 High School International Department   \n",
      "1  Zhuhai No.1 High School International Department   \n",
      "2  Zhuhai No.1 High School International Department   \n",
      "\n",
      "              Similar Institution   Recommended Categories  \\\n",
      "0                    NIT-Agartala  Internship, Competition   \n",
      "1  Nuhu Bamalli Polytechnic Zaria  Internship, Competition   \n",
      "2    North maharashtra university  Internship, Competition   \n",
      "\n",
      "   Avg Completion Rate  \n",
      "0                  0.5  \n",
      "1                  0.5  \n",
      "2                  0.5  \n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# COLLABORATIVE FILTERING (Enhanced)\n",
    "# -------------------------------\n",
    "\n",
    "# Create a pivot table: institution vs. opportunity_category\n",
    "# Each cell = average completion rate for that category at that institution\n",
    "pivot_df = data.pivot_table(\n",
    "    index='institution_name',\n",
    "    columns='opportunity_category',\n",
    "    values='completion_flag',\n",
    "    aggfunc='mean'\n",
    ").fillna(0)\n",
    "\n",
    "# Compute cosine similarity between institutions\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "inst_similarity = cosine_similarity(pivot_df)\n",
    "inst_sim_df = pd.DataFrame(inst_similarity, index=pivot_df.index, columns=pivot_df.index)\n",
    "\n",
    "# Function: Recommend similar institutions and their high-performing categories\n",
    "def recommend_institution_patterns(institution_name, top_n=3):\n",
    "    if institution_name not in inst_sim_df.index:\n",
    "        return f\"Institution '{institution_name}' not found in dataset.\"\n",
    "    \n",
    "    # Step 1: Get top similar institutions\n",
    "    similar_institutions = inst_sim_df[institution_name].sort_values(ascending=False).index[1:top_n+1]\n",
    "    \n",
    "    # Step 2: For each similar institution, get their top-performing opportunity categories\n",
    "    recommendations = []\n",
    "    for inst in similar_institutions:\n",
    "        top_categories = pivot_df.loc[inst].sort_values(ascending=False).head(2).index.tolist()\n",
    "        avg_success = pivot_df.loc[inst, top_categories].mean()\n",
    "        recommendations.append({\n",
    "            'Reference Institution': institution_name,\n",
    "            'Similar Institution': inst,\n",
    "            'Recommended Categories': ', '.join(top_categories),\n",
    "            'Avg Completion Rate': round(avg_success, 2)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(recommendations)\n",
    "\n",
    "# Example usage\n",
    "sample_institution = data['institution_name'].iloc[0]\n",
    "print(f\"\\nðŸ‘¥ Collaborative Recommendations for '{sample_institution}':\")\n",
    "collab_results = recommend_institution_patterns(sample_institution)\n",
    "print(collab_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c36780e3-6e86-4fa0-9eee-dc3dcabd2266",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m scaled_features = scaler.fit_transform(content_encoded[content_features])\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Compute cosine similarity\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m similarity_matrix = \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m similarity_df = pd.DataFrame(similarity_matrix, index=content_encoded.index, columns=content_encoded.index)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Function to recommend similar opportunities\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ds_env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ds_env\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1728\u001b[39m, in \u001b[36mcosine_similarity\u001b[39m\u001b[34m(X, Y, dense_output)\u001b[39m\n\u001b[32m   1675\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m   1676\u001b[39m     {\n\u001b[32m   1677\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msparse matrix\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1682\u001b[39m )\n\u001b[32m   1683\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcosine_similarity\u001b[39m(X, Y=\u001b[38;5;28;01mNone\u001b[39;00m, dense_output=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1684\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[32m   1685\u001b[39m \n\u001b[32m   1686\u001b[39m \u001b[33;03m    Cosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1726\u001b[39m \u001b[33;03m           [0.577, 0.816]])\u001b[39;00m\n\u001b[32m   1727\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1728\u001b[39m     X, Y = \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1730\u001b[39m     X_normalized = normalize(X, copy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1731\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ds_env\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:190\u001b[39m, in \u001b[36mcheck_pairwise_arrays\u001b[39m\u001b[34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_all_finite, ensure_2d, copy)\u001b[39m\n\u001b[32m    187\u001b[39m     dtype = dtype_float\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m X \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     X = Y = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    200\u001b[39m     X = check_array(\n\u001b[32m    201\u001b[39m         X,\n\u001b[32m    202\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   (...)\u001b[39m\u001b[32m    207\u001b[39m         ensure_2d=ensure_2d,\n\u001b[32m    208\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ds_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:1105\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m     )\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1114\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ds_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\ds_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# CONTENT-BASED FILTERING\n",
    "# -------------------------------\n",
    "\n",
    "# Make a copy and keep the original category for reference\n",
    "content_df = data.copy()\n",
    "\n",
    "# Save category names separately before encoding\n",
    "original_categories = content_df[['opportunity_name', 'opportunity_category', 'opportunity_duration', 'institution_name']]\n",
    "\n",
    "# Encode the opportunity category\n",
    "content_encoded = pd.get_dummies(content_df, columns=['opportunity_category'], drop_first=True)\n",
    "\n",
    "# Select features for similarity\n",
    "content_features = ['opportunity_duration', 'apply_lag', 'start_lag'] + \\\n",
    "                   [col for col in content_encoded.columns if col.startswith('opportunity_category_')]\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(content_encoded[content_features])\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarity_matrix = cosine_similarity(scaled_features)\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=content_encoded.index, columns=content_encoded.index)\n",
    "\n",
    "# Function to recommend similar opportunities\n",
    "def recommend_opportunities(index, top_n=3):\n",
    "    similar_indices = similarity_df[index].sort_values(ascending=False).index[1:top_n+1]\n",
    "    # pull from original (non-encoded) columns for readability\n",
    "    return data.loc[similar_indices, ['opportunity_name', 'opportunity_category', 'opportunity_duration', 'institution_name']]\n",
    "\n",
    "# Example usage\n",
    "print(\"\\nðŸŽ¯ Content-Based Recommendations for the first opportunity:\")\n",
    "print(recommend_opportunities(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b86a62-3528-4d0d-b245-a0b59039d53d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds_env)",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
